Policy gradient practice:
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/girafe-ai/ml-mipt/blob/21f_advanced/week1_10_reinforce/practice_reinforce.ipynb)

Binpord's policy gradient practice:
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/girafe-ai/ml-mipt/blob/21f_advanced/week1_10_reinforce/binpord_practice_reinforce_clean.ipynb)

Further readings:

- Actually proving the policy gradient for discounted rewards -
  [article](https://papers.nips.cc/paper/1713-policy-gradient-methods-for-reinforcement-learning-with-function-approximation.pdf)
- On variance of policy gradient and optimal baselines:
  [article](https://papers.nips.cc/paper/4264-analysis-and-improvement-of-policy-gradient-estimation.pdf),
  another [article](https://arxiv.org/pdf/1301.2315.pdf)

\_Based on
[Practical_RL week06](https://github.com/yandexdataschool/Practical_RL/tree/master/week06_policy_based)
